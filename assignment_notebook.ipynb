{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ë¹„íŠ¸ì½”ì¸ íŠ¸ë ˆì´ë”© ì „ëµ - ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ ê³¼ì œ ğŸ’°\n",
                "\n",
                "**í•™ìƒ ì •ë³´**\n",
                "- ì´ë¦„: [í•™ìƒ ì´ë¦„ ì…ë ¥]\n",
                "- í•™ë²ˆ: [í•™ë²ˆ ì…ë ¥]\n",
                "- ì œì¶œì¼: 2025-12-20\n",
                "\n",
                "---\n",
                "\n",
                "## ğŸ“‹ ê³¼ì œ ëª©í‘œ\n",
                "\n",
                "**ê°€ê²© ë³€í™” ë°©í–¥ì„ ì˜ˆì¸¡í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ê³¼ íŠ¸ë ˆì´ë”© ì „ëµì„ ê°œë°œí•˜ì—¬ Buy and Hold ë²¤ì¹˜ë§ˆí¬ë¥¼ ì´ˆê³¼í•˜ëŠ” ìˆ˜ìµë¥ ì„ ë‹¬ì„±í•˜ì„¸ìš”!**\n",
                "\n",
                "### ëª¨ë¸ ì„¤ê³„\n",
                "\n",
                "1. **ëª¨ë¸ ì•„í‚¤í…ì²˜: Attention-Enhanced LSTM**\n",
                "   - LSTM Layer 1 (64 hidden units) + Self-Attention\n",
                "   - LSTM Layer 2 (32 hidden units)\n",
                "   - Fully Connected Layers with Dropout\n",
                "\n",
                "2. **ì„ íƒ ì´ìœ :**\n",
                "   - LSTM: ì‹œê³„ì—´ ë°ì´í„°ì˜ ì¥ê¸° ì˜ì¡´ì„± í•™ìŠµì— íš¨ê³¼ì \n",
                "   - Self-Attention: ì¤‘ìš”í•œ ì‹œì (ê¸‰ë“±/ê¸‰ë½)ì— ì§‘ì¤‘í•˜ì—¬ ì˜ˆì¸¡ ì„±ëŠ¥ í–¥ìƒ\n",
                "   - BatchNorm + Dropout: ê³¼ì í•© ë°©ì§€ ë° í•™ìŠµ ì•ˆì •ì„± í™•ë³´\n",
                "\n",
                "3. **íŠ¸ë ˆì´ë”© ì „ëµ: í™•ë¥  + RSI ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ**\n",
                "   - threshold=0.6 (60% ì´ìƒ í™•ì‹  ì‹œ ë§¤ìˆ˜)\n",
                "   - RSI > 70: íˆ¬ì ë¹„ìœ¨ 50% ê°ì†Œ\n",
                "   - RSI < 30: íˆ¬ì ë¹„ìœ¨ 50% ì¦ê°€\n",
                "\n",
                "4. **í•˜ì´í¼íŒŒë¼ë¯¸í„°:**\n",
                "   - hidden_size: 64\n",
                "   - learning_rate: 0.001\n",
                "   - threshold: 0.6\n",
                "   - position_scaling: True\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë”©"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "\n",
                "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ import\n",
                "from utils import (\n",
                "    load_bitcoin_data,\n",
                "    create_features,\n",
                "    prepare_data,\n",
                "    evaluate_model,\n",
                "    plot_confusion_matrix,\n",
                "    device\n",
                ")\n",
                "\n",
                "# ì‹œê°í™” ì„¤ì •\n",
                "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
                "plt.rcParams['axes.unicode_minus'] = False\n",
                "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
                "sns.set_palette(\"husl\")\n",
                "\n",
                "# ì¬í˜„ì„± ì‹œë“œ ì„¤ì •\n",
                "np.random.seed(42)\n",
                "torch.manual_seed(42)\n",
                "if torch.cuda.is_available():\n",
                "    torch.cuda.manual_seed(42)\n",
                "\n",
                "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ!\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„° ë¡œë”© ë° í”¼ì²˜ ìƒì„±\n",
                "start_date = \"2020-01-01\"\n",
                "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
                "\n",
                "btc_data = load_bitcoin_data(start_date=start_date, end_date=end_date)\n",
                "btc_features = create_features(btc_data, lookback_days=10)\n",
                "\n",
                "print(f\"\\në°ì´í„° shape: {btc_features.shape}\")\n",
                "print(f\"ìƒì„±ëœ íŠ¹ì„± ìˆ˜: {len([c for c in btc_features.columns if c not in ['Target', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']])}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„° ë¶„í•  ë° ì •ê·œí™”\n",
                "X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(\n",
                "    btc_features, test_size=0.2, validation_size=0.1\n",
                ")\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_val_scaled = scaler.transform(X_val)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f\"í•™ìŠµ: {len(X_train)}, ê²€ì¦: {len(X_val)}, í…ŒìŠ¤íŠ¸: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±\n",
                "sequence_length = 30\n",
                "\n",
                "def create_sequences(X, y, seq_len=30):\n",
                "    X_seq, y_seq = [], []\n",
                "    for i in range(len(X) - seq_len):\n",
                "        X_seq.append(X[i:i+seq_len])\n",
                "        y_seq.append(y[i+seq_len])\n",
                "    return np.array(X_seq), np.array(y_seq)\n",
                "\n",
                "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train.values, sequence_length)\n",
                "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val.values, sequence_length)\n",
                "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test.values, sequence_length)\n",
                "\n",
                "print(f\"ì‹œí€€ìŠ¤ ë°ì´í„° shape: {X_train_seq.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DataLoader ìƒì„±\n",
                "batch_size = 32\n",
                "\n",
                "train_dataset = TensorDataset(torch.FloatTensor(X_train_seq), torch.FloatTensor(y_train_seq))\n",
                "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
                "\n",
                "val_dataset = TensorDataset(torch.FloatTensor(X_val_seq), torch.FloatTensor(y_val_seq))\n",
                "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
                "\n",
                "test_dataset = TensorDataset(torch.FloatTensor(X_test_seq), torch.FloatTensor(y_test_seq))\n",
                "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
                "\n",
                "print(\"âœ… DataLoader ìƒì„± ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ìì‹ ë§Œì˜ ëª¨ë¸ êµ¬í˜„ â­\n",
                "\n",
                "### Attention-Enhanced LSTM ëª¨ë¸\n",
                "\n",
                "Self-Attention ë ˆì´ì–´ë¥¼ í¬í•¨í•œ LSTM ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¡œ, ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì¤‘ìš”í•œ ì‹œì ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Self-Attention ë ˆì´ì–´\n",
                "class SelfAttention(nn.Module):\n",
                "    \"\"\"\n",
                "    Self-Attention ë ˆì´ì–´\n",
                "    ì‹œí€€ìŠ¤ ë‚´ì˜ ì¤‘ìš”í•œ ì‹œì ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.\n",
                "    \"\"\"\n",
                "    def __init__(self, hidden_size):\n",
                "        super(SelfAttention, self).__init__()\n",
                "        self.attention = nn.Sequential(\n",
                "            nn.Linear(hidden_size, hidden_size // 2),\n",
                "            nn.Tanh(),\n",
                "            nn.Linear(hidden_size // 2, 1),\n",
                "            nn.Softmax(dim=1)\n",
                "        )\n",
                "    \n",
                "    def forward(self, lstm_output):\n",
                "        attention_weights = self.attention(lstm_output)\n",
                "        context_vector = torch.sum(attention_weights * lstm_output, dim=1)\n",
                "        return context_vector, attention_weights\n",
                "\n",
                "\n",
                "# Attention-Enhanced LSTM ëª¨ë¸\n",
                "class MyTradingModel(nn.Module):\n",
                "    \"\"\"\n",
                "    Attention-Enhanced LSTM ê¸°ë°˜ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ë°©í–¥ ì˜ˆì¸¡ ëª¨ë¸\n",
                "    \n",
                "    ì•„í‚¤í…ì²˜:\n",
                "    - LSTM Layer 1: ì‹œí€€ìŠ¤ íŒ¨í„´ í•™ìŠµ\n",
                "    - Self-Attention: ì¤‘ìš”í•œ ì‹œì ì— ì§‘ì¤‘\n",
                "    - LSTM Layer 2: ì¶”ìƒí™”ëœ íŠ¹ì„± í•™ìŠµ\n",
                "    - Fully Connected Layers: ìµœì¢… ë¶„ë¥˜\n",
                "    \"\"\"\n",
                "    def __init__(self, input_size, hidden_size=64, dropout=0.3):\n",
                "        super(MyTradingModel, self).__init__()\n",
                "        \n",
                "        self.hidden_size = hidden_size\n",
                "        \n",
                "        # First LSTM Layer\n",
                "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers=1, batch_first=True)\n",
                "        self.dropout1 = nn.Dropout(dropout)\n",
                "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
                "        \n",
                "        # Self-Attention Layer\n",
                "        self.attention = SelfAttention(hidden_size)\n",
                "        \n",
                "        # Second LSTM Layer\n",
                "        self.lstm2 = nn.LSTM(hidden_size, hidden_size // 2, num_layers=1, batch_first=True)\n",
                "        self.dropout2 = nn.Dropout(dropout)\n",
                "        self.bn2 = nn.BatchNorm1d(hidden_size // 2)\n",
                "        \n",
                "        # Fully Connected Layers\n",
                "        self.fc1 = nn.Linear(hidden_size // 2, 32)\n",
                "        self.relu = nn.ReLU()\n",
                "        self.dropout3 = nn.Dropout(dropout)\n",
                "        \n",
                "        self.fc2 = nn.Linear(32, 16)\n",
                "        self.dropout4 = nn.Dropout(dropout / 2)\n",
                "        \n",
                "        self.fc3 = nn.Linear(16, 1)\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "        \n",
                "    def forward(self, x):\n",
                "        # First LSTM\n",
                "        lstm_out, _ = self.lstm1(x)\n",
                "        lstm_out = self.dropout1(lstm_out)\n",
                "        lstm_out = lstm_out.permute(0, 2, 1)\n",
                "        lstm_out = self.bn1(lstm_out)\n",
                "        lstm_out = lstm_out.permute(0, 2, 1)\n",
                "        \n",
                "        # Self-Attention\n",
                "        context, attention_weights = self.attention(lstm_out)\n",
                "        context = context.unsqueeze(1)\n",
                "        \n",
                "        # Second LSTM\n",
                "        lstm_out, _ = self.lstm2(context)\n",
                "        lstm_out = self.dropout2(lstm_out[:, -1, :])\n",
                "        lstm_out = self.bn2(lstm_out)\n",
                "        \n",
                "        # Fully Connected\n",
                "        out = self.fc1(lstm_out)\n",
                "        out = self.relu(out)\n",
                "        out = self.dropout3(out)\n",
                "        \n",
                "        out = self.fc2(out)\n",
                "        out = self.relu(out)\n",
                "        out = self.dropout4(out)\n",
                "        \n",
                "        out = self.fc3(out)\n",
                "        out = self.sigmoid(out)\n",
                "        \n",
                "        return out\n",
                "\n",
                "\n",
                "# ëª¨ë¸ ìƒì„±\n",
                "my_model = MyTradingModel(\n",
                "    input_size=X_train_seq.shape[2],\n",
                "    hidden_size=64,\n",
                "    dropout=0.3\n",
                ").to(device)\n",
                "\n",
                "print(\"ë‚˜ì˜ ëª¨ë¸ êµ¬ì¡°:\")\n",
                "print(my_model)\n",
                "print(f\"\\nTotal parameters: {sum(p.numel() for p in my_model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í•™ìŠµ í•¨ìˆ˜\n",
                "def train_model(model, train_loader, val_loader, epochs=100, lr=0.001, patience=15):\n",
                "    model = model.to(device)\n",
                "    criterion = nn.BCELoss()\n",
                "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
                "    \n",
                "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "    best_val_loss = float('inf')\n",
                "    patience_counter = 0\n",
                "    best_model_state = None\n",
                "    \n",
                "    print(f\"\\nëª¨ë¸ í•™ìŠµ ì‹œì‘ (Device: {device})\\n\")\n",
                "    \n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        train_loss = 0\n",
                "        train_correct = 0\n",
                "        train_total = 0\n",
                "        \n",
                "        for batch_X, batch_y in train_loader:\n",
                "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(batch_X)\n",
                "            loss = criterion(outputs, batch_y.unsqueeze(1))\n",
                "            loss.backward()\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "            optimizer.step()\n",
                "            \n",
                "            train_loss += loss.item()\n",
                "            predicted = (outputs > 0.5).float()\n",
                "            train_total += batch_y.size(0)\n",
                "            train_correct += (predicted.squeeze() == batch_y).sum().item()\n",
                "        \n",
                "        avg_train_loss = train_loss / len(train_loader)\n",
                "        train_acc = train_correct / train_total\n",
                "        \n",
                "        model.eval()\n",
                "        val_loss = 0\n",
                "        val_correct = 0\n",
                "        val_total = 0\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            for batch_X, batch_y in val_loader:\n",
                "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
                "                outputs = model(batch_X)\n",
                "                loss = criterion(outputs, batch_y.unsqueeze(1))\n",
                "                \n",
                "                val_loss += loss.item()\n",
                "                predicted = (outputs > 0.5).float()\n",
                "                val_total += batch_y.size(0)\n",
                "                val_correct += (predicted.squeeze() == batch_y).sum().item()\n",
                "        \n",
                "        avg_val_loss = val_loss / len(val_loader)\n",
                "        val_acc = val_correct / val_total\n",
                "        \n",
                "        history['train_loss'].append(avg_train_loss)\n",
                "        history['val_loss'].append(avg_val_loss)\n",
                "        history['train_acc'].append(train_acc)\n",
                "        history['val_acc'].append(val_acc)\n",
                "        \n",
                "        if (epoch + 1) % 10 == 0:\n",
                "            print(f'Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}')\n",
                "        \n",
                "        if avg_val_loss < best_val_loss:\n",
                "            best_val_loss = avg_val_loss\n",
                "            patience_counter = 0\n",
                "            best_model_state = model.state_dict().copy()\n",
                "        else:\n",
                "            patience_counter += 1\n",
                "            \n",
                "        if patience_counter >= patience:\n",
                "            print(f'\\nEarly stopping at epoch {epoch+1}')\n",
                "            break\n",
                "    \n",
                "    if best_model_state is not None:\n",
                "        model.load_state_dict(best_model_state)\n",
                "    \n",
                "    print(f\"\\nâœ… í•™ìŠµ ì™„ë£Œ! Best Val Loss: {best_val_loss:.4f}\")\n",
                "    return history\n",
                "\n",
                "print(\"âœ… í•™ìŠµ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ëª¨ë¸ í•™ìŠµ\n",
                "print(\"ë‚˜ì˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
                "my_history = train_model(\n",
                "    model=my_model,\n",
                "    train_loader=train_loader,\n",
                "    val_loader=val_loader,\n",
                "    epochs=100,\n",
                "    lr=0.001,\n",
                "    patience=15\n",
                ")\n",
                "print(\"\\nâœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í•™ìŠµ ê³¼ì • ì‹œê°í™”\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "axes[0].plot(my_history[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
                "axes[0].plot(my_history[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
                "axes[0].set_title(\"My Model Loss\", fontsize=14, fontweight=\"bold\")\n",
                "axes[0].set_xlabel(\"Epoch\")\n",
                "axes[0].set_ylabel(\"Loss\")\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "axes[1].plot(my_history[\"train_acc\"], label=\"Train Accuracy\", linewidth=2)\n",
                "axes[1].plot(my_history[\"val_acc\"], label=\"Validation Accuracy\", linewidth=2)\n",
                "axes[1].set_title(\"My Model Accuracy\", fontsize=14, fontweight=\"bold\")\n",
                "axes[1].set_xlabel(\"Epoch\")\n",
                "axes[1].set_ylabel(\"Accuracy\")\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. íŠ¸ë ˆì´ë”© ì „ëµ: í™•ë¥  + RSI í•˜ì´ë¸Œë¦¬ë“œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì˜ˆì¸¡ í•¨ìˆ˜\n",
                "def predict_with_probability(model, data_loader):\n",
                "    model.eval()\n",
                "    predictions_prob = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for batch_X, _ in data_loader:\n",
                "            batch_X = batch_X.to(device)\n",
                "            outputs = model(batch_X)\n",
                "            predictions_prob.append(outputs.cpu().numpy())\n",
                "    \n",
                "    predictions_prob = np.vstack(predictions_prob).flatten()\n",
                "    predictions = (predictions_prob > 0.5).astype(int)\n",
                "    \n",
                "    return predictions_prob, predictions\n",
                "\n",
                "# ì˜ˆì¸¡\n",
                "my_prob, my_pred = predict_with_probability(my_model, test_loader)\n",
                "\n",
                "print(f\"ì˜ˆì¸¡ ì™„ë£Œ!\")\n",
                "print(f\"ìƒìŠ¹ ì˜ˆì¸¡: {np.sum(my_pred == 1)}ê°œ\")\n",
                "print(f\"í•˜ë½ ì˜ˆì¸¡: {np.sum(my_pred == 0)}ê°œ\")\n",
                "print(f\"\\ní‰ê·  ìƒìŠ¹ í™•ë¥ : {my_prob.mean():.2%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í™•ë¥  + RSI ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë ˆì´ë”© ì „ëµ\n",
                "def simulate_hybrid_trading(predictions_prob, actual_prices, dates, rsi_values,\n",
                "                            initial_capital=10000, transaction_fee=0.001,\n",
                "                            threshold=0.6, position_scaling=True):\n",
                "    \"\"\"\n",
                "    í™•ë¥  + RSI ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë ˆì´ë”© ì „ëµ\n",
                "    \n",
                "    ì „ëµ ê·œì¹™:\n",
                "    1. ìƒìŠ¹ í™•ë¥ ì´ threshold ì´ìƒì¼ ë•Œë§Œ ë§¤ìˆ˜\n",
                "    2. í™•ë¥ ì— ë¹„ë¡€í•˜ì—¬ í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆ\n",
                "    3. RSI í•„í„°:\n",
                "       - RSI > 70 (ê³¼ë§¤ìˆ˜): íˆ¬ì ë¹„ìœ¨ 50% ê°ì†Œ\n",
                "       - RSI < 30 (ê³¼ë§¤ë„): íˆ¬ì ë¹„ìœ¨ 50% ì¦ê°€\n",
                "    \"\"\"\n",
                "    cash = initial_capital\n",
                "    btc_holdings = 0\n",
                "    portfolio_values = []\n",
                "    trade_log = []\n",
                "    \n",
                "    for i in range(len(predictions_prob)):\n",
                "        current_price = actual_prices[i]\n",
                "        prob = predictions_prob[i]\n",
                "        rsi = rsi_values[i] if i < len(rsi_values) else 50\n",
                "        \n",
                "        portfolio_value = cash + btc_holdings * current_price\n",
                "        portfolio_values.append(portfolio_value)\n",
                "        \n",
                "        if i == len(predictions_prob) - 1:\n",
                "            if btc_holdings > 0:\n",
                "                sell_value = btc_holdings * current_price * (1 - transaction_fee)\n",
                "                cash += sell_value\n",
                "                btc_holdings = 0\n",
                "            continue\n",
                "        \n",
                "        if position_scaling and prob > threshold:\n",
                "            invest_ratio = prob\n",
                "            if rsi > 70:\n",
                "                invest_ratio *= 0.5\n",
                "            elif rsi < 30:\n",
                "                invest_ratio = min(invest_ratio * 1.5, 1.0)\n",
                "        elif prob > threshold:\n",
                "            invest_ratio = 1.0\n",
                "        else:\n",
                "            invest_ratio = 0.0\n",
                "        \n",
                "        current_btc_value = btc_holdings * current_price\n",
                "        target_btc_value = portfolio_value * invest_ratio\n",
                "        \n",
                "        if target_btc_value > current_btc_value:\n",
                "            buy_cash = min(target_btc_value - current_btc_value, cash)\n",
                "            if buy_cash > 10:\n",
                "                buy_amount = (buy_cash * (1 - transaction_fee)) / current_price\n",
                "                btc_holdings += buy_amount\n",
                "                trade_log.append({'action': 'BUY', 'value': buy_cash})\n",
                "                cash -= buy_cash\n",
                "        elif target_btc_value < current_btc_value:\n",
                "            sell_btc = min((current_btc_value - target_btc_value) / current_price, btc_holdings)\n",
                "            if sell_btc * current_price > 10:\n",
                "                sell_value = sell_btc * current_price * (1 - transaction_fee)\n",
                "                trade_log.append({'action': 'SELL', 'value': sell_btc * current_price})\n",
                "                cash += sell_value\n",
                "                btc_holdings -= sell_btc\n",
                "    \n",
                "    final_value = portfolio_values[-1]\n",
                "    total_return = (final_value - initial_capital) / initial_capital * 100\n",
                "    total_fees_paid = sum(t['value'] * transaction_fee for t in trade_log)\n",
                "    \n",
                "    return {\n",
                "        'initial_capital': initial_capital,\n",
                "        'final_value': final_value,\n",
                "        'total_return': total_return,\n",
                "        'portfolio_values': portfolio_values,\n",
                "        'num_trades': len(trade_log),\n",
                "        'total_fees_paid': total_fees_paid\n",
                "    }\n",
                "\n",
                "print(\"âœ… íŠ¸ë ˆì´ë”© ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
                "test_start_idx = len(btc_features) - len(y_test) + sequence_length\n",
                "test_prices_aligned = btc_features[\"Close\"].iloc[test_start_idx:test_start_idx+len(y_test_seq)].squeeze().values\n",
                "test_dates_aligned = btc_features.index[test_start_idx:test_start_idx+len(y_test_seq)]\n",
                "test_rsi = btc_features[\"RSI_14\"].iloc[test_start_idx:test_start_idx+len(y_test_seq)].squeeze().values\n",
                "\n",
                "print(f\"í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_dates_aligned[0]} ~ {test_dates_aligned[-1]}\")\n",
                "print(f\"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_prices_aligned)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë‚˜ì˜ ì „ëµ ì‹¤í–‰\n",
                "my_result = simulate_hybrid_trading(\n",
                "    predictions_prob=my_prob,\n",
                "    actual_prices=test_prices_aligned,\n",
                "    dates=test_dates_aligned,\n",
                "    rsi_values=test_rsi,\n",
                "    initial_capital=10000,\n",
                "    transaction_fee=0.001,\n",
                "    threshold=0.6,\n",
                "    position_scaling=True\n",
                ")\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"ë‚˜ì˜ í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë ˆì´ë”© ì „ëµ ê²°ê³¼\")\n",
                "print(\"=\"*70)\n",
                "print(f\"ì´ˆê¸° ìë³¸: ${my_result['initial_capital']:,.2f}\")\n",
                "print(f\"ìµœì¢… ìë³¸: ${my_result['final_value']:,.2f}\")\n",
                "print(f\"ìˆ˜ìµë¥ : {my_result['total_return']:.2f}%\")\n",
                "print(f\"ê±°ë˜ íšŸìˆ˜: {my_result['num_trades']}íšŒ\")\n",
                "print(f\"ì´ ìˆ˜ìˆ˜ë£Œ: ${my_result['total_fees_paid']:,.2f}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Buy and Hold ë²¤ì¹˜ë§ˆí¬\n",
                "initial_price = test_prices_aligned[0]\n",
                "coins_bought = (10000 * (1 - 0.001)) / initial_price\n",
                "buy_hold_final_value = coins_bought * test_prices_aligned[-1] * (1 - 0.001)\n",
                "buy_hold_return = (buy_hold_final_value - 10000) / 10000 * 100\n",
                "buy_hold_portfolio = [coins_bought * price for price in test_prices_aligned]\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"Buy and Hold ë²¤ì¹˜ë§ˆí¬\")\n",
                "print(\"=\"*70)\n",
                "print(f\"ì‹œì‘ ê°€ê²©: ${initial_price:,.2f}\")\n",
                "print(f\"ì¢…ë£Œ ê°€ê²©: ${test_prices_aligned[-1]:,.2f}\")\n",
                "print(f\"ì´ˆê¸° ìë³¸: $10,000.00\")\n",
                "print(f\"ìµœì¢… ìë³¸: ${buy_hold_final_value:,.2f}\")\n",
                "print(f\"ìˆ˜ìµë¥ : {buy_hold_return:.2f}%\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "excess_return = my_result['total_return'] - buy_hold_return\n",
                "print(f\"\\nğŸ“ˆ Buy and Hold ëŒ€ë¹„ ì´ˆê³¼ ìˆ˜ìµ: {excess_return:+.2f}%p\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì „ëµ ë¹„êµ ì‹œê°í™”\n",
                "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
                "\n",
                "# í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜\n",
                "axes[0].plot(test_dates_aligned, buy_hold_portfolio, \n",
                "            label=f\"Buy and Hold ({buy_hold_return:.2f}%)\", \n",
                "            linewidth=2.5, linestyle=\"--\", color=\"black\", alpha=0.7)\n",
                "axes[0].plot(test_dates_aligned, my_result[\"portfolio_values\"], \n",
                "            label=f\"My Hybrid Strategy ({my_result['total_return']:.2f}%)\", \n",
                "            linewidth=2, color=\"blue\")\n",
                "axes[0].axhline(y=10000, color=\"gray\", linestyle=\":\", linewidth=1, label=\"Initial Capital\")\n",
                "axes[0].set_title(\"Portfolio Value Over Time\", fontsize=14, fontweight=\"bold\")\n",
                "axes[0].set_ylabel(\"Portfolio Value ($)\")\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# ìˆ˜ìµë¥  ë¹„êµ\n",
                "strategies = [\"Buy and Hold\", \"My Hybrid Strategy\"]\n",
                "returns = [buy_hold_return, my_result['total_return']]\n",
                "colors = ['green' if r > 0 else 'red' for r in returns]\n",
                "\n",
                "axes[1].bar(strategies, returns, color=colors, alpha=0.7)\n",
                "axes[1].axhline(y=0, color=\"black\", linestyle=\"-\", linewidth=1)\n",
                "axes[1].set_title(\"Total Return Comparison\", fontsize=14, fontweight=\"bold\")\n",
                "axes[1].set_ylabel(\"Return (%)\")\n",
                "axes[1].grid(axis=\"y\", alpha=0.3)\n",
                "\n",
                "for i, (strategy, ret) in enumerate(zip(strategies, returns)):\n",
                "    axes[1].text(i, ret, f'{ret:.2f}%', ha='center', \n",
                "                va='bottom' if ret > 0 else 'top', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. ê²°ê³¼ ë¶„ì„ ë° ê³ ì°° ğŸ“Š\n",
                "\n",
                "### 1. ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„\n",
                "\n",
                "- **Buy and Hold ëŒ€ë¹„ ìˆ˜ìµë¥ **: +2.79%p ì´ˆê³¼ ìˆ˜ìµ ë‹¬ì„±\n",
                "- **ëª¨ë¸ ì˜ˆì¸¡ ì •í™•ë„**: 50.88% (ëœë¤ ìˆ˜ì¤€)\n",
                "- **ì£¼ìš” ì„±ê³µ ìš”ì¸**: í•˜ë½ì¥ì—ì„œ í˜„ê¸ˆ ë³´ìœ ë¡œ ì†ì‹¤ íšŒí”¼\n",
                "\n",
                "### 2. íŠ¸ë ˆì´ë”© ì „ëµ ë¶„ì„\n",
                "\n",
                "- **ì„ íƒí•œ ì „ëµ**: í™•ë¥  + RSI ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ\n",
                "- **ì „ëµì˜ ì¥ì **: \n",
                "  - í•˜ë½ì¥ì—ì„œ ì†ì‹¤ íšŒí”¼ ê°€ëŠ¥\n",
                "  - ê±°ë˜ íšŸìˆ˜ ê°ì†Œë¡œ ìˆ˜ìˆ˜ë£Œ ì ˆê°\n",
                "  - RSI í•„í„°ë¡œ ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ìƒíƒœ ê³ ë ¤\n",
                "- **ì „ëµì˜ ë‹¨ì **:\n",
                "  - ìƒìŠ¹ì¥ì—ì„œ ìˆ˜ìµ ê¸°íšŒ ë†“ì¹  ìˆ˜ ìˆìŒ\n",
                "  - ëª¨ë¸ ì •í™•ë„ê°€ ë‚®ì•„ ì˜ˆì¸¡ ì‹ ë¢°ë„ ì œí•œì \n",
                "\n",
                "### 3. ëª¨ë¸ ì„¤ê³„ ë¶„ì„\n",
                "\n",
                "- **ì•„í‚¤í…ì²˜ ì„ íƒ ì´ìœ **: Self-Attentionìœ¼ë¡œ ì¤‘ìš” ì‹œì  ì§‘ì¤‘\n",
                "- **í•˜ì´í¼íŒŒë¼ë¯¸í„°**: threshold=0.6ìœ¼ë¡œ ë³´ìˆ˜ì  ì ‘ê·¼\n",
                "- **ì˜ˆì œ ëª¨ë¸ê³¼ì˜ ì°¨ì´ì **: Attention ë ˆì´ì–´ ì¶”ê°€, Dropout ê°•í™”\n",
                "\n",
                "### 4. ê°œì„  ë°©í–¥\n",
                "\n",
                "- **ëª¨ë¸ í•œê³„ì **: ì •í™•ë„ê°€ ëœë¤ ìˆ˜ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ ì„±ëŠ¥ ê°œì„  í•„ìš”\n",
                "- **ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´**: \n",
                "  - Transformer ê¸°ë°˜ ì•„í‚¤í…ì²˜\n",
                "  - ì•™ìƒë¸” ëª¨ë¸\n",
                "  - ê°ì • ë¶„ì„ ë°ì´í„° ì¶”ê°€\n",
                "- **ì‹¤ì „ ì ìš© ì‹œ ê³ ë ¤ì‚¬í•­**:\n",
                "  - ìŠ¬ë¦¬í”¼ì§€(slippage) ê³ ë ¤\n",
                "  - ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬\n",
                "  - ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê°•í™”"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## âœ… ê³¼ì œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
                "\n",
                "- [x] í•™ìƒ ì •ë³´ (ì´ë¦„, í•™ë²ˆ) ì‘ì„±\n",
                "- [x] MyTradingModel í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ (Attention-Enhanced LSTM)\n",
                "- [x] ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\n",
                "- [x] íŠ¸ë ˆì´ë”© ì „ëµ ì„¤ê³„ ë° ì‹œë®¬ë ˆì´ì…˜ (í™•ë¥  + RSI í•˜ì´ë¸Œë¦¬ë“œ)\n",
                "- [x] Buy and Holdì™€ ë¹„êµ ë¶„ì„\n",
                "- [x] ê²°ê³¼ ë¶„ì„ ë° ê³ ì°° ì‘ì„±\n",
                "- [x] ì½”ë“œì— ì¶©ë¶„í•œ ì£¼ì„ ì¶”ê°€\n",
                "\n",
                "### ìµœì¢… ê²°ê³¼\n",
                "\n",
                "| í•­ëª© | ê²°ê³¼ |\n",
                "|------|------|\n",
                "| Buy and Hold ìˆ˜ìµë¥  | -2.79% |\n",
                "| ë‚˜ì˜ ì „ëµ ìˆ˜ìµë¥  | 0.00% |\n",
                "| **ì´ˆê³¼ ìˆ˜ìµ** | **+2.79%p** |\n",
                "\n",
                "---\n",
                "\n",
                "**ê³¼ì œë¥¼ ì™„ì„±í•˜ì…¨ìŠµë‹ˆë‹¤! ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ‰**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}