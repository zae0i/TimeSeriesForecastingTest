"""
ë¹„íŠ¸ì½”ì¸ íŠ¸ë ˆì´ë”© ì „ëµ - ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. ë¹„íŠ¸ì½”ì¸ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
2. Attention-Enhanced LSTM ëª¨ë¸ í›ˆë ¨
3. í™•ë¥  + RSI ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ íˆ¬ì ì „ëµ ì‹œë®¬ë ˆì´ì…˜
4. Buy and Hold ë²¤ì¹˜ë§ˆí¬ì™€ ë¹„êµ
5. ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
"""

import os
import json
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.preprocessing import StandardScaler

import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader

# utils.pyì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ import
from utils import (
    load_bitcoin_data,
    create_features,
    prepare_data,
    evaluate_model,
    device
)

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)

# ì‹œê°í™” ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
plt.style.use("seaborn-v0_8-darkgrid")
sns.set_palette("husl")

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
RESULTS_DIR = "results"
os.makedirs(RESULTS_DIR, exist_ok=True)


# ============================================
# 1. ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜
# ============================================

class SelfAttention(nn.Module):
    """
    Self-Attention ë ˆì´ì–´
    ì‹œí€€ìŠ¤ ë‚´ì˜ ì¤‘ìš”í•œ ì‹œì ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
    """
    def __init__(self, hidden_size):
        super(SelfAttention, self).__init__()
        self.attention = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.Tanh(),
            nn.Linear(hidden_size // 2, 1),
            nn.Softmax(dim=1)
        )
    
    def forward(self, lstm_output):
        # lstm_output: (batch, seq_len, hidden_size)
        attention_weights = self.attention(lstm_output)  # (batch, seq_len, 1)
        context_vector = torch.sum(attention_weights * lstm_output, dim=1)  # (batch, hidden_size)
        return context_vector, attention_weights


class MyTradingModel(nn.Module):
    """
    Attention-Enhanced LSTM ê¸°ë°˜ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ë°©í–¥ ì˜ˆì¸¡ ëª¨ë¸
    
    ì•„í‚¤í…ì²˜:
    - LSTM Layer 1: ì‹œí€€ìŠ¤ íŒ¨í„´ í•™ìŠµ
    - Self-Attention: ì¤‘ìš”í•œ ì‹œì ì— ì§‘ì¤‘
    - LSTM Layer 2: ì¶”ìƒí™”ëœ íŠ¹ì„± í•™ìŠµ
    - Fully Connected Layers: ìµœì¢… ë¶„ë¥˜
    
    ì¶œë ¥: ìƒìŠ¹ í™•ë¥  (0~1)
    """
    def __init__(self, input_size, hidden_size=64, dropout=0.3):
        super(MyTradingModel, self).__init__()
        
        self.hidden_size = hidden_size
        
        # First LSTM Layer
        self.lstm1 = nn.LSTM(
            input_size, hidden_size, 
            num_layers=1, batch_first=True, bidirectional=False
        )
        self.dropout1 = nn.Dropout(dropout)
        self.bn1 = nn.BatchNorm1d(hidden_size)
        
        # Self-Attention Layer
        self.attention = SelfAttention(hidden_size)
        
        # Second LSTM Layer
        self.lstm2 = nn.LSTM(
            hidden_size, hidden_size // 2,
            num_layers=1, batch_first=True
        )
        self.dropout2 = nn.Dropout(dropout)
        self.bn2 = nn.BatchNorm1d(hidden_size // 2)
        
        # Fully Connected Layers
        self.fc1 = nn.Linear(hidden_size // 2, 32)
        self.relu = nn.ReLU()
        self.dropout3 = nn.Dropout(dropout)
        
        self.fc2 = nn.Linear(32, 16)
        self.dropout4 = nn.Dropout(dropout / 2)
        
        self.fc3 = nn.Linear(16, 1)
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        # x: (batch, seq_len, input_size)
        
        # First LSTM
        lstm_out, _ = self.lstm1(x)  # (batch, seq_len, hidden_size)
        lstm_out = self.dropout1(lstm_out)
        
        # BatchNorm (needs permutation)
        lstm_out = lstm_out.permute(0, 2, 1)  # (batch, hidden_size, seq_len)
        lstm_out = self.bn1(lstm_out)
        lstm_out = lstm_out.permute(0, 2, 1)  # (batch, seq_len, hidden_size)
        
        # Self-Attention
        context, attention_weights = self.attention(lstm_out)  # (batch, hidden_size)
        
        # Reshape for second LSTM
        context = context.unsqueeze(1)  # (batch, 1, hidden_size)
        
        # Second LSTM
        lstm_out, _ = self.lstm2(context)
        lstm_out = self.dropout2(lstm_out[:, -1, :])  # (batch, hidden_size//2)
        lstm_out = self.bn2(lstm_out)
        
        # Fully Connected Layers
        out = self.fc1(lstm_out)
        out = self.relu(out)
        out = self.dropout3(out)
        
        out = self.fc2(out)
        out = self.relu(out)
        out = self.dropout4(out)
        
        out = self.fc3(out)
        out = self.sigmoid(out)
        
        return out


# ============================================
# 2. í•™ìŠµ í•¨ìˆ˜
# ============================================

def train_model(model, train_loader, val_loader, epochs=100, lr=0.001, patience=15):
    """
    ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ (Early Stopping í¬í•¨)
    """
    model = model.to(device)
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5
    )
    
    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}
    best_val_loss = float('inf')
    patience_counter = 0
    best_model_state = None
    
    print(f"\n{'='*60}")
    print(f"ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Device: {device})")
    print(f"{'='*60}")
    
    for epoch in range(epochs):
        # Training phase
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        
        for batch_X, batch_y in train_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y.unsqueeze(1))
            loss.backward()
            
            # Gradient clipping to prevent exploding gradients
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            train_loss += loss.item()
            predicted = (outputs > 0.5).float()
            train_total += batch_y.size(0)
            train_correct += (predicted.squeeze() == batch_y).sum().item()
        
        avg_train_loss = train_loss / len(train_loader)
        train_acc = train_correct / train_total
        
        # Validation phase
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for batch_X, batch_y in val_loader:
                batch_X, batch_y = batch_X.to(device), batch_y.to(device)
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y.unsqueeze(1))
                
                val_loss += loss.item()
                predicted = (outputs > 0.5).float()
                val_total += batch_y.size(0)
                val_correct += (predicted.squeeze() == batch_y).sum().item()
        
        avg_val_loss = val_loss / len(val_loader)
        val_acc = val_correct / val_total
        
        # Learning rate scheduling
        scheduler.step(avg_val_loss)
        
        # Record history
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(avg_val_loss)
        history['train_acc'].append(train_acc)
        history['val_acc'].append(val_acc)
        
        if (epoch + 1) % 10 == 0:
            print(f'Epoch [{epoch+1}/{epochs}] | '
                  f'Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | '
                  f'Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}')
        
        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            best_model_state = model.state_dict().copy()
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            print(f'\nEarly stopping at epoch {epoch+1}')
            break
    
    # Load best model
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! Best Val Loss: {best_val_loss:.4f}")
    return history


def predict_with_probability(model, data_loader):
    """
    ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ë° í™•ë¥  ë°˜í™˜
    """
    model.eval()
    predictions_prob = []
    
    with torch.no_grad():
        for batch_X, _ in data_loader:
            batch_X = batch_X.to(device)
            outputs = model(batch_X)
            predictions_prob.append(outputs.cpu().numpy())
    
    predictions_prob = np.vstack(predictions_prob).flatten()
    predictions = (predictions_prob > 0.5).astype(int)
    
    return predictions_prob, predictions


# ============================================
# 3. í•˜ì´ë¸Œë¦¬ë“œ íˆ¬ì ì „ëµ
# ============================================

def simulate_hybrid_trading(predictions_prob, actual_prices, dates, rsi_values,
                            initial_capital=10000, transaction_fee=0.001,
                            threshold=0.6, position_scaling=True):
    """
    í™•ë¥  + RSI ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ íŠ¸ë ˆì´ë”© ì „ëµ
    
    ì „ëµ ê·œì¹™:
    1. ìƒìŠ¹ í™•ë¥ ì´ threshold ì´ìƒì¼ ë•Œë§Œ ë§¤ìˆ˜
    2. í™•ë¥ ì— ë¹„ë¡€í•˜ì—¬ í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆ
    3. RSI í•„í„°:
       - RSI > 70 (ê³¼ë§¤ìˆ˜): íˆ¬ì ë¹„ìœ¨ 50% ê°ì†Œ
       - RSI < 30 (ê³¼ë§¤ë„): íˆ¬ì ë¹„ìœ¨ 50% ì¦ê°€
    4. í•˜ë½ ì˜ˆì¸¡ ì‹œ ë³´ìœ  ìì‚° ë§¤ë„
    """
    cash = initial_capital
    btc_holdings = 0
    portfolio_values = []
    trade_log = []
    
    for i in range(len(predictions_prob)):
        current_price = actual_prices[i]
        prob = predictions_prob[i]
        rsi = rsi_values[i] if i < len(rsi_values) else 50  # RSI ê¸°ë³¸ê°’
        
        portfolio_value = cash + btc_holdings * current_price
        portfolio_values.append(portfolio_value)
        
        # ë§ˆì§€ë§‰ ë‚  ì „ëŸ‰ ë§¤ë„
        if i == len(predictions_prob) - 1:
            if btc_holdings > 0:
                sell_value = btc_holdings * current_price * (1 - transaction_fee)
                trade_log.append({
                    'date': str(dates[i]),
                    'action': 'SELL_ALL',
                    'price': current_price,
                    'prob': prob,
                    'rsi': rsi,
                    'amount': btc_holdings,
                    'value': btc_holdings * current_price,
                    'fee': btc_holdings * current_price * transaction_fee
                })
                cash += sell_value
                btc_holdings = 0
            continue
        
        # íˆ¬ì ë¹„ìœ¨ ê²°ì •
        if position_scaling and prob > threshold:
            # ê¸°ë³¸ íˆ¬ì ë¹„ìœ¨ = í™•ë¥ 
            invest_ratio = prob
            
            # RSI í•„í„° ì ìš©
            if rsi > 70:  # ê³¼ë§¤ìˆ˜ ìƒíƒœ
                invest_ratio *= 0.5  # íˆ¬ì ë¹„ìœ¨ 50% ê°ì†Œ
            elif rsi < 30:  # ê³¼ë§¤ë„ ìƒíƒœ
                invest_ratio = min(invest_ratio * 1.5, 1.0)  # íˆ¬ì ë¹„ìœ¨ 50% ì¦ê°€
        elif prob > threshold:
            invest_ratio = 1.0
        else:
            invest_ratio = 0.0
        
        # í˜„ì¬ í¬ì§€ì…˜ ë¹„ìœ¨
        current_btc_value = btc_holdings * current_price
        target_btc_value = portfolio_value * invest_ratio
        
        # í¬ì§€ì…˜ ì¡°ì •
        if target_btc_value > current_btc_value:  # ë§¤ìˆ˜ í•„ìš”
            buy_cash = min(target_btc_value - current_btc_value, cash)
            if buy_cash > 10:  # ìµœì†Œ ê±°ë˜ ê¸ˆì•¡
                buy_amount = (buy_cash * (1 - transaction_fee)) / current_price
                btc_holdings += buy_amount
                trade_log.append({
                    'date': str(dates[i]),
                    'action': 'BUY',
                    'price': current_price,
                    'prob': prob,
                    'rsi': rsi,
                    'amount': buy_amount,
                    'value': buy_cash,
                    'fee': buy_cash * transaction_fee
                })
                cash -= buy_cash
                
        elif target_btc_value < current_btc_value:  # ë§¤ë„ í•„ìš”
            sell_btc = min((current_btc_value - target_btc_value) / current_price, btc_holdings)
            if sell_btc * current_price > 10:  # ìµœì†Œ ê±°ë˜ ê¸ˆì•¡
                sell_value = sell_btc * current_price * (1 - transaction_fee)
                trade_log.append({
                    'date': str(dates[i]),
                    'action': 'SELL',
                    'price': current_price,
                    'prob': prob,
                    'rsi': rsi,
                    'amount': sell_btc,
                    'value': sell_btc * current_price,
                    'fee': sell_btc * current_price * transaction_fee
                })
                cash += sell_value
                btc_holdings -= sell_btc
    
    final_value = portfolio_values[-1]
    total_return = (final_value - initial_capital) / initial_capital * 100
    total_trade_volume = sum(trade['value'] for trade in trade_log)
    total_fees_paid = sum(trade['fee'] for trade in trade_log)
    
    return {
        'initial_capital': initial_capital,
        'final_value': final_value,
        'total_return': total_return,
        'portfolio_values': portfolio_values,
        'trade_log': trade_log,
        'num_trades': len(trade_log),
        'total_trade_volume': total_trade_volume,
        'total_fees_paid': total_fees_paid,
        'dates': dates
    }


# ============================================
# 4. ì‹œê°í™” í•¨ìˆ˜
# ============================================

def plot_training_history(history, save_path):
    """í•™ìŠµ ê³¼ì • ì‹œê°í™”"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Loss
    axes[0].plot(history["train_loss"], label="Train Loss", linewidth=2, color='#3498db')
    axes[0].plot(history["val_loss"], label="Validation Loss", linewidth=2, color='#e74c3c')
    axes[0].set_title("Model Loss", fontsize=14, fontweight="bold")
    axes[0].set_xlabel("Epoch")
    axes[0].set_ylabel("Loss")
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # Accuracy
    axes[1].plot(history["train_acc"], label="Train Accuracy", linewidth=2, color='#3498db')
    axes[1].plot(history["val_acc"], label="Validation Accuracy", linewidth=2, color='#e74c3c')
    axes[1].set_title("Model Accuracy", fontsize=14, fontweight="bold")
    axes[1].set_xlabel("Epoch")
    axes[1].set_ylabel("Accuracy")
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š í•™ìŠµ ê·¸ë˜í”„ ì €ì¥: {save_path}")


def plot_portfolio_comparison(results_dict, dates, save_path):
    """í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµ ì‹œê°í™”"""
    fig, axes = plt.subplots(2, 1, figsize=(14, 10))
    
    # 1. í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™”
    colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6']
    for idx, (name, result) in enumerate(results_dict.items()):
        if 'portfolio_values' in result:
            style = '--' if name == 'Buy and Hold' else '-'
            lw = 2.5 if name == 'Buy and Hold' else 2
            axes[0].plot(
                dates[:len(result['portfolio_values'])], 
                result['portfolio_values'],
                label=f"{name} ({result['total_return']:.2f}%)",
                linewidth=lw, linestyle=style, color=colors[idx % len(colors)]
            )
    
    axes[0].axhline(y=10000, color='gray', linestyle=':', linewidth=1, label='Initial Capital')
    axes[0].set_title('Portfolio Value Over Time', fontsize=14, fontweight='bold')
    axes[0].set_ylabel('Portfolio Value ($)')
    axes[0].legend(loc='upper left')
    axes[0].grid(True, alpha=0.3)
    
    # 2. ìˆ˜ìµë¥  ë¹„êµ ë°” ì°¨íŠ¸
    strategies = list(results_dict.keys())
    returns = [results_dict[s]['total_return'] for s in strategies]
    bar_colors = ['#2ecc71' if r > 0 else '#e74c3c' for r in returns]
    
    bars = axes[1].bar(strategies, returns, color=bar_colors, alpha=0.8, edgecolor='black')
    axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)
    axes[1].set_title('Total Return Comparison', fontsize=14, fontweight='bold')
    axes[1].set_ylabel('Return (%)')
    axes[1].grid(axis='y', alpha=0.3)
    
    for bar, ret in zip(bars, returns):
        height = bar.get_height()
        axes[1].text(bar.get_x() + bar.get_width()/2., height,
                    f'{ret:.2f}%', ha='center', 
                    va='bottom' if ret > 0 else 'top', fontweight='bold', fontsize=11)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµ ê·¸ë˜í”„ ì €ì¥: {save_path}")


# ============================================
# 5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================

def create_sequences(X, y, seq_len=30):
    """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±"""
    X_seq, y_seq = [], []
    for i in range(len(X) - seq_len):
        X_seq.append(X[i:i+seq_len])
        y_seq.append(y[i+seq_len])
    return np.array(X_seq), np.array(y_seq)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸš€ ë¹„íŠ¸ì½”ì¸ íŠ¸ë ˆì´ë”© ì „ëµ - ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€")
    print("="*60)
    
    # ----- Step 1: ë°ì´í„° ë¡œë”© -----
    print("\nğŸ“¥ Step 1: ë°ì´í„° ë¡œë”©...")
    start_date = "2020-01-01"
    end_date = datetime.now().strftime("%Y-%m-%d")
    
    btc_data = load_bitcoin_data(start_date=start_date, end_date=end_date)
    btc_features = create_features(btc_data, lookback_days=10)
    
    print(f"ë°ì´í„° shape: {btc_features.shape}")
    print(f"ê¸°ê°„: {btc_features.index[0]} ~ {btc_features.index[-1]}")
    
    # ----- Step 2: ë°ì´í„° ë¶„í•  ë° ì „ì²˜ë¦¬ -----
    print("\nğŸ“Š Step 2: ë°ì´í„° ë¶„í•  ë° ì „ì²˜ë¦¬...")
    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(
        btc_features, test_size=0.2, validation_size=0.1
    )
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    # ì‹œí€€ìŠ¤ ìƒì„±
    sequence_length = 30
    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train.values, sequence_length)
    X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val.values, sequence_length)
    X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test.values, sequence_length)
    
    print(f"ì‹œí€€ìŠ¤ ë°ì´í„° shape: {X_train_seq.shape}")
    
    # DataLoader ìƒì„±
    batch_size = 32
    train_dataset = TensorDataset(torch.FloatTensor(X_train_seq), torch.FloatTensor(y_train_seq))
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    
    val_dataset = TensorDataset(torch.FloatTensor(X_val_seq), torch.FloatTensor(y_val_seq))
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    test_dataset = TensorDataset(torch.FloatTensor(X_test_seq), torch.FloatTensor(y_test_seq))
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    # ----- Step 3: ëª¨ë¸ ìƒì„± ë° í•™ìŠµ -----
    print("\nğŸ§  Step 3: ëª¨ë¸ ìƒì„± ë° í•™ìŠµ...")
    model = MyTradingModel(
        input_size=X_train_seq.shape[2],
        hidden_size=64,
        dropout=0.3
    ).to(device)
    
    print(f"ëª¨ë¸ êµ¬ì¡°:\n{model}")
    print(f"Total parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    history = train_model(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=100,
        lr=0.001,
        patience=15
    )
    
    # í•™ìŠµ ê·¸ë˜í”„ ì €ì¥
    plot_training_history(history, os.path.join(RESULTS_DIR, "training_history.png"))
    
    # ----- Step 4: ëª¨ë¸ í‰ê°€ -----
    print("\nğŸ“ˆ Step 4: ëª¨ë¸ í‰ê°€...")
    my_prob, my_pred = predict_with_probability(model, test_loader)
    
    metrics = evaluate_model(y_test_seq, my_pred, model_name="MyTradingModel")
    
    print(f"ì˜ˆì¸¡ ì™„ë£Œ!")
    print(f"ìƒìŠ¹ ì˜ˆì¸¡: {np.sum(my_pred == 1)}ê°œ")
    print(f"í•˜ë½ ì˜ˆì¸¡: {np.sum(my_pred == 0)}ê°œ")
    print(f"í‰ê·  ìƒìŠ¹ í™•ë¥ : {my_prob.mean():.2%}")
    
    # ----- Step 5: íŠ¸ë ˆì´ë”© ì‹œë®¬ë ˆì´ì…˜ -----
    print("\nğŸ’° Step 5: íŠ¸ë ˆì´ë”© ì‹œë®¬ë ˆì´ì…˜...")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    test_start_idx = len(btc_features) - len(y_test) + sequence_length
    test_prices = btc_features["Close"].iloc[test_start_idx:test_start_idx+len(y_test_seq)].squeeze().values
    test_dates = btc_features.index[test_start_idx:test_start_idx+len(y_test_seq)]
    test_rsi = btc_features["RSI_14"].iloc[test_start_idx:test_start_idx+len(y_test_seq)].squeeze().values
    
    print(f"í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_dates[0]} ~ {test_dates[-1]}")
    
    # ì „ëµ 1: í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ (í™•ë¥  + RSI)
    my_result = simulate_hybrid_trading(
        predictions_prob=my_prob,
        actual_prices=test_prices,
        dates=test_dates,
        rsi_values=test_rsi,
        initial_capital=10000,
        transaction_fee=0.001,
        threshold=0.6,
        position_scaling=True
    )
    
    # Buy and Hold ë²¤ì¹˜ë§ˆí¬
    initial_price = test_prices[0]
    coins_bought = (10000 * (1 - 0.001)) / initial_price
    buy_hold_final_value = coins_bought * test_prices[-1] * (1 - 0.001)
    buy_hold_return = (buy_hold_final_value - 10000) / 10000 * 100
    buy_hold_portfolio = [coins_bought * price for price in test_prices]
    
    buy_hold_result = {
        'initial_capital': 10000,
        'final_value': buy_hold_final_value,
        'total_return': buy_hold_return,
        'portfolio_values': buy_hold_portfolio,
        'num_trades': 2,
        'total_fees_paid': 10000 * 0.001 + coins_bought * test_prices[-1] * 0.001
    }
    
    # ----- Step 6: ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥ -----
    print("\n" + "="*70)
    print("ğŸ“Š íŠ¸ë ˆì´ë”© ì „ëµ ê²°ê³¼ ë¹„êµ")
    print("="*70)
    
    print(f"\n{'ì „ëµ':<25} {'ìµœì¢…ìë³¸':>15} {'ìˆ˜ìµë¥ ':>12} {'ê±°ë˜íšŸìˆ˜':>10} {'ìˆ˜ìˆ˜ë£Œ':>12}")
    print("-"*70)
    print(f"{'Buy and Hold':<25} ${buy_hold_result['final_value']:>14,.2f} {buy_hold_result['total_return']:>11.2f}% {buy_hold_result['num_trades']:>10} ${buy_hold_result['total_fees_paid']:>11,.2f}")
    print(f"{'My Hybrid Strategy':<25} ${my_result['final_value']:>14,.2f} {my_result['total_return']:>11.2f}% {my_result['num_trades']:>10} ${my_result['total_fees_paid']:>11,.2f}")
    print("-"*70)
    
    excess_return = my_result['total_return'] - buy_hold_result['total_return']
    print(f"\nğŸ“ˆ Buy and Hold ëŒ€ë¹„ ì´ˆê³¼ ìˆ˜ìµ: {excess_return:+.2f}%p")
    
    if excess_return > 0:
        print("âœ… ë²¤ì¹˜ë§ˆí¬ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!")
    else:
        print("âŒ ë²¤ì¹˜ë§ˆí¬ì— ë¯¸ë‹¬í–ˆìŠµë‹ˆë‹¤.")
    
    # í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµ ê·¸ë˜í”„ ì €ì¥
    results_dict = {
        'Buy and Hold': buy_hold_result,
        'My Hybrid Strategy': my_result
    }
    plot_portfolio_comparison(results_dict, test_dates, os.path.join(RESULTS_DIR, "portfolio_comparison.png"))
    
    # ê²°ê³¼ JSON ì €ì¥
    results_json = {
        'test_period': {
            'start': str(test_dates[0]),
            'end': str(test_dates[-1])
        },
        'model_metrics': {
            'accuracy': metrics['accuracy'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1': metrics['f1']
        },
        'buy_and_hold': {
            'initial_capital': buy_hold_result['initial_capital'],
            'final_value': round(buy_hold_result['final_value'], 2),
            'total_return': round(buy_hold_result['total_return'], 2),
            'num_trades': buy_hold_result['num_trades']
        },
        'my_strategy': {
            'initial_capital': my_result['initial_capital'],
            'final_value': round(my_result['final_value'], 2),
            'total_return': round(my_result['total_return'], 2),
            'num_trades': my_result['num_trades'],
            'total_fees_paid': round(my_result['total_fees_paid'], 2)
        },
        'excess_return': round(excess_return, 2)
    }
    
    with open(os.path.join(RESULTS_DIR, "results.json"), 'w', encoding='utf-8') as f:
        json.dump(results_json, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {RESULTS_DIR}/")
    print("  - training_history.png")
    print("  - portfolio_comparison.png")
    print("  - results.json")
    
    print("\n" + "="*60)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("="*60)
    
    return results_json


if __name__ == "__main__":
    results = main()
